# Perceptron
Deepak Nalla – Intro to AI – Perceptron README doc.

The assignment uses pandas and numpy modules in python. generate_features.py -> It takes all the training images, both from train8 and trainOthers and generate feature matrix. It also puts in the relevant label(1 or -1) and shuffles the matrix for better training.

perceptron_trains.py: It utilises the feature matrix generated by earlier code and update weights with the update routine. It saves the weights in a file.

evaluate.py: Given a test image, it generates the feature vector for the same and finds the output(1 for 8 and -1 for not 8) using weights generated before.
These are the parameters I used:
num_features = 600
WEIGHTS = [0 for i in range(1,602)]
LEARNING_RATE = .10
MAX_ITERATIONS = 10
BIAS = .10

The number of features in my feature matrix is 600, because of 30 columns * 20 rows, and this is the standard size to store the input(data) in. The weights are taken from 1, 602 to account for bias,etc. While the learning rate which is used along with the xvec value and multiplied times the error and is to be added to the weights.

The max iterations parameter holds the number of iterations for the perceptron training, and I put it initially at 10, because that is the minimum number of repetitions one needs in order to get it close to 0 misclassifications. I also found for a number of images, around 2 repetitions which has around a little <20 misclassifications should be enough to evaluate the image.txt file. It takes about 15 iterations to ensure misclassifications are always =0

The bias I put is .10 which is a helpful parameter in computing the function values, and adjusting the weights slightly accounting for any offset.